# KV Cache Code Structure & API Reference\n\n## File Organization\n\n```\nCortexStream/\n├── include/cortexstream/kv_cache.h      (490 lines)\n│   ├── struct KVHandle                   (8 lines)\n│   ├── class KVBlockAllocator            (75 lines)\n│   ├── struct Tensor                     (4 lines)\n│   ├── struct SequenceKVEntry            (4 lines)\n│   └── class KVCache                     (280 lines)\n│\n├── src/cache/kv_cache.cpp                (520 lines)\n│   ├── KVBlockAllocator::allocate()      (16 lines)\n│   ├── KVBlockAllocator::free()          (10 lines)\n│   ├── KVBlockAllocator::findContiguousFreeRegion() (21 lines)\n│   ├── KVCache::allocateFor()            (21 lines)\n│   ├── KVCache::freeFor()                (10 lines)\n│   ├── KVCache::getKView()               (12 lines)\n│   ├── KVCache::getVView()               (12 lines)\n│   ├── KVCache::appendToken()            (13 lines)\n│   ├── KVCache::getKBuffer()             (8 lines)\n│   ├── KVCache::getVBuffer()             (8 lines)\n│   └── Statistics & debug methods\n│\n├── docs/KV_CACHE_DESIGN.md               (600 lines)\n├── docs/TRITON_COMPARISON.md             (400 lines)\n├── docs/KV_CACHE_INTEGRATION.md          (300 lines)\n└── KV_CACHE_IMPLEMENTATION.md            (420 lines)\n```\n\n---\n\n## API Reference\n\n### KVHandle (Data Structure)\n\n```cpp\nstruct KVHandle {\n    int startBlockIndex;    // First block in allocation\n    int numBlocks;          // Number of blocks allocated\n    \n    bool isValid() const {\n        return startBlockIndex >= 0 && numBlocks > 0;\n    }\n};\n```\n\n**Usage:**\n```cpp\nKVHandle handle = allocator.allocate(32);\nif (handle.isValid()) {\n    // Allocation succeeded\n} else {\n    // OOM: allocation failed\n}\n```\n\n---\n\n### KVBlockAllocator (Physical Layer)\n\n#### Constructor\n```cpp\nexplicit KVBlockAllocator(size_t totalBlocks);\n```\n\n**Parameters:**\n- `totalBlocks`: Total number of fixed-size blocks in pool\n\n**Example:**\n```cpp\nconst size_t maxTokens = 32768;\nconst size_t blockSize = 16;\nsize_t totalBlocks = (maxTokens + blockSize - 1) / blockSize;  // 2048\nauto allocator = std::make_unique<KVBlockAllocator>(totalBlocks);\n```\n\n#### allocate()\n```cpp\nKVHandle allocate(int blocksNeeded);\n```\n\n**Parameters:**\n- `blocksNeeded`: Number of contiguous blocks requested\n\n**Returns:**\n- Valid `KVHandle` on success\n- Invalid handle (startBlockIndex < 0) on OOM\n\n**Time Complexity:** O(totalBlocks) MVP\n\n**Example:**\n```cpp\nint blocksNeeded = 32;  // For 512 token sequence\nKVHandle handle = allocator.allocate(blocksNeeded);\n\nif (handle.isValid()) {\n    // Blocks [handle.startBlockIndex, +handle.numBlocks) are yours\n} else {\n    // Out of memory\n}\n```\n\n#### free()\n```cpp\nvoid free(const KVHandle& handle);\n```\n\n**Parameters:**\n- `handle`: Handle returned from allocate()\n\n**Behavior:**\n- Marks blocks as free immediately\n- No validation (invalid handles are no-op)\n- Blocks available for reuse\n\n**Example:**\n```cpp\nallocator.free(handle);  // Instantly available for reuse\n```\n\n#### Statistics Methods\n\n```cpp\nsize_t freeBlocks() const;          // Number of unallocated blocks\nsize_t usedBlocks() const;          // Number of allocated blocks\nsize_t totalBlocks() const;         // Total pool size\nfloat fragmentation() const;        // 0.0 = perfect, 1.0 = worst\nvoid dumpBlockMap(std::ostream& os); // ASCII visualization\n```\n\n**Example:**\n```cpp\nif (allocator.freeBlocks() == 0) {\n    std::cerr << \"KV cache pool exhausted!\\n\";\n    std::cerr << \"Fragmentation: \" << allocator.fragmentation() << \"\\n\";\n}\n```\n\n---\n\n### KVCache (Logical Layer)\n\n#### Constructor\n```cpp\nexplicit KVCache(size_t numLayers,\n                 size_t numHeads,\n                 size_t headDim,\n                 size_t maxTotalTokens,\n                 size_t blockSize = 16);\n```\n\n**Parameters:**\n- `numLayers`: Number of transformer layers (typically 32)\n- `numHeads`: Attention heads per layer (typically 32)\n- `headDim`: Dimension of each head (typically 64)\n- `maxTotalTokens`: Total tokens across all sequences (typically 32768)\n- `blockSize`: Tokens per block (default 16)\n\n**Memory Allocation:**\nPreallocates K and V buffers:\n```cpp\nsize_t elementsPerLayer = maxTotalTokens/blockSize * numHeads * blockSize * headDim\nsize_t totalBytes = numLayers * elementsPerLayer * 2 * sizeof(float)\n```\n\n**Example:**\n```cpp\nKVCache cache(\n    32,     // layers\n    32,     // heads\n    64,     // headDim\n    32768,  // maxTotalTokens\n    16      // blockSize\n);\ncache.warmup();  // Touch pages for instant allocation\n```\n\n#### allocateFor()\n```cpp\nbool allocateFor(const std::string& requestId, int initialTokens);\n```\n\n**Parameters:**\n- `requestId`: Unique sequence identifier\n- `initialTokens`: Initial token count (prompt length)\n\n**Returns:**\n- `true` on success\n- `false` on OOM\n\n**Guarantees:**\n- Contiguous block allocation\n- No partial allocation on failure\n- Sequence can grow up to maxAllowed tokens\n\n**Example:**\n```cpp\nconst std::vector<int> prompt = {1, 2, 3, ..., 512};\nbool success = cache.allocateFor(\"user_123\", prompt.size());\n\nif (!success) {\n    // OOM: rejection policy\n    request.setState(RequestState::Failed);\n    return;\n}\n\n// Prefill can proceed\n```\n\n#### freeFor()\n```cpp\nvoid freeFor(const std::string& requestId);\n```\n\n**Parameters:**\n- `requestId`: Sequence to free\n\n**Behavior:**\n- Returns blocks to allocator\n- Removes sequence tracking\n- Blocks immediately available for reuse\n\n**Example:**\n```cpp\ncache.freeFor(\"user_123\");  // Instant cleanup, no GC\n```\n\n#### getKView()\n```cpp\nTensor getKView(const std::string& requestId, int layer);\n```\n\n**Parameters:**\n- `requestId`: Sequence identifier\n- `layer`: Transformer layer index (0 to numLayers-1)\n\n**Returns:**\n- `Tensor` with:\n  - `data`: Pointer to K arena memory (layer, layer)\n  - `shape`: {numHeads, tokensUsed, headDim}\n  - `valid`: True if sequence exists\n\n**Zero-Copy Guarantee:**\n- Returns direct arena pointer\n- No data movement\n- MLX can use immediately\n\n**Example:**\n```cpp\nTensor k_view = cache.getKView(\"user_123\", layer_0);\n\nif (!k_view.valid) {\n    // Sequence not found\n    return;\n}\n\n// MLX operation on arena memory directly\nmlx::array K = mlx::array(\n    k_view.data,\n    {k_view.shape[0], k_view.shape[1], k_view.shape[2]}\n);\n```\n\n#### getVView()\n```cpp\nTensor getVView(const std::string& requestId, int layer);\n```\n\n**Parameters:** Same as `getKView()`\n\n**Returns:** V tensor view (same layout as K)\n\n#### usedTokens()\n```cpp\nint usedTokens(const std::string& requestId) const;\n```\n\n**Returns:** Current token count for sequence\n\n**Example:**\n```cpp\nint tokens = cache.usedTokens(\"user_123\");\nstd::cout << \"Current length: \" << tokens << \"\\n\";\n```\n\n#### appendToken()\n```cpp\nbool appendToken(const std::string& requestId);\n```\n\n**Returns:**\n- `true` if token added successfully\n- `false` if sequence at capacity\n\n**Behavior:**\n- Increments tokensUsed counter\n- Tokens stay within allocated blocks (no fragmentation)\n\n**Example:**\n```cpp\n// After sampling token in decode loop\nint token = sampler.sampleToken(logits, ...);\nrequest.addToken(token);\n\nif (!cache.appendToken(\"user_123\")) {\n    // Sequence exhausted allocated blocks\n    request.setState(RequestState::Failed);\n    continue;\n}\n```\n\n#### getTokenOffsetInBlock()\n```cpp\nint getTokenOffsetInBlock(const std::string& requestId) const;\n```\n\n**Returns:** Offset within current block (0 to blockSize-1)\n\n**Usage:** For backend to know where to write KV values\n\n**Example:**\n```cpp\nint offset = cache.getTokenOffsetInBlock(\"user_123\");\n// Write new token KV to this offset in the appropriate block\n```\n\n#### Statistics Methods\n\n```cpp\nsize_t getTotalAllocated() const;      // Bytes allocated to sequences\nsize_t getTotalFree() const;           // Bytes available for allocation\nint getNumAllocatedSequences() const;  // Active sequences\nbool isFull() const;                   // Boolean: out of memory\nfloat getFragmentation() const;        // 0.0 = perfect\nvoid dumpCacheStats(std::ostream& os); // Detailed dump\n```\n\n**Example:**\n```cpp\nsize_t allocated_mb = cache.getTotalAllocated() / 1024 / 1024;\nsize_t free_mb = cache.getTotalFree() / 1024 / 1024;\nint seqs = cache.getNumAllocatedSequences();\nfloat frag = cache.getFragmentation();\n\nstd::cout << std::format(\n    \"KV: {}/{} MB ({} seqs, frag={:.2f})\",\n    allocated_mb, allocated_mb + free_mb, seqs, frag\n);\n\nif (cache.isFull()) {\n    // Reject new requests\n}\n```\n\n#### dumpCacheStats()\n```cpp\nvoid dumpCacheStats(std::ostream& os) const;\n```\n\n**Output:**\n```\n=== KVCache Statistics ===\nConfiguration:\n  Layers: 32, Heads: 32, HeadDim: 64\n  BlockSize: 16, TotalBlocks: 2048\n\nAllocation State:\n  Allocated sequences: 5\n  Total allocated: 1024.00 MB\n  Total free: 7168.00 MB\n  Fragmentation: 0.05\n\nSequences:\n  req_001: 512/512 tokens, blocks [0, +32]\n  req_002: 256/512 tokens, blocks [32, +32]\n  ...\n```\n\n#### warmup()\n```cpp\nvoid warmup();\n```\n\n**Purpose:** Touch memory pages to ensure allocation succeeds immediately\n\n**Call before:** Starting inference (in Engine init)\n\n---\n\n## Tensor Structure\n\n```cpp\nstruct Tensor {\n    float* data;                    // Pointer to memory\n    std::vector<size_t> shape;      // Dimensions\n    bool valid;                     // Whether tensor is valid\n};\n```\n\n**Example:**\n```cpp\nTensor view = cache.getKView(\"user_123\", 0);\n\nif (view.valid) {\n    // view.data points to arena memory\n    // view.shape = {32, 512, 64}  (heads, tokens, headDim)\n    \n    // Use with MLX\n    mlx::array arr = mlx::array(\n        view.data,\n        {view.shape[0], view.shape[1], view.shape[2]}\n    );\n}\n```\n\n---\n\n## Error Handling Patterns\n\n### OOM on Allocation\n\n```cpp\nif (!cache.allocateFor(requestId, promptLength)) {\n    // Strategy 1: Reject\n    request->setState(RequestState::Failed);\n    \n    // Strategy 2: Reduce max tokens\n    int maxTokens = request->getMaxTokens() / 2;\n    if (cache.allocateFor(requestId, promptLength)) {\n        request->setMaxTokens(maxTokens);\n    }\n    \n    // Strategy 3: Queue for retry\n    scheduler->defer(request);\n}\n```\n\n### Null View\n\n```cpp\nTensor k_view = cache.getKView(requestId, layer);\n\nif (!k_view.valid) {\n    // Sequence not found\n    // Options:\n    // 1. Use default cache (zeros)\n    // 2. Skip layer\n    // 3. Error\n    std::cerr << \"Sequence \" << requestId << \" not found\\n\";\n}\n```\n\n### Capacity Exceeded\n\n```cpp\nif (!cache.appendToken(requestId)) {\n    // Sequence at max capacity\n    // Stop generation\n    request->setState(RequestState::Finished);\n}\n```\n\n---\n\n## Memory Calculation Examples\n\n### Example 1: 7B LLaMA\n\n```cpp\nconst size_t numLayers = 32;\nconst size_t numHeads = 32;\nconst size_t headDim = 64;\nconst size_t blockSize = 16;\nconst size_t maxTokens = 32768;  // 32K context\n\n// Calculation\nsize_t totalBlocks = (maxTokens + blockSize - 1) / blockSize;  // 2048\nsize_t elementsPerBlock = numHeads * blockSize * headDim;      // 32,768\nsize_t elementsPerLayer = totalBlocks * elementsPerBlock;      // 67M\nsize_t totalElements = numLayers * elementsPerLayer * 2;       // 4.3B\nsize_t totalBytes = totalElements * sizeof(float);              // 17.2 GB\n\n// Result: 17.2 GB for K+V combined\n```\n\n### Example 2: Smaller Model (3B)\n\n```cpp\nconst size_t numLayers = 24;\nconst size_t numHeads = 24;\nconst size_t headDim = 64;\nconst size_t blockSize = 16;\nconst size_t maxTokens = 16384;  // 16K context\n\nsize_t totalBlocks = (16384 + 16 - 1) / 16;  // 1024\nsize_t totalElements = 24 * 1024 * 24 * 16 * 64 * 2;\nsize_t totalBytes = totalElements * 4;  // ~3.1 GB\n```\n\n---\n\n## Thread Safety\n\n### Current (MVP)\n\n**All operations protected with `std::mutex`:**\n\n```cpp\nstd::lock_guard<std::mutex> guard(lock_);\n// Critical section\n// Auto-release on scope exit\n```\n\n**Safe for:**\n- Single-threaded engine loop\n- Multiple scheduler threads submitting requests\n- Reads during inference (concurrent getKView/getVView)\n\n### Future Upgrades\n\n- Lock-free allocation queue\n- Per-block spinlocks for read concurrency\n- RCU (Read-Copy-Update) for view access\n\n---\n\n## Performance Tips\n\n### Memory Efficiency\n\n```cpp\n// Tune blockSize based on latency requirements\nbool allocateFor(...) depends on (maxTokens / blockSize) blocks\n\n// blockSize = 16:  More blocks, higher overhead, lower latency variance\n// blockSize = 64:  Fewer blocks, better throughput, higher latency spikes\n```\n\n### Allocation Performance\n\n```cpp\n// MVP: O(totalBlocks) scan\n// For 2048 blocks on modern CPU: ~1-2 microseconds\n// Negligible compared to forward pass time\n\n// Future: Buddy allocator O(log totalBlocks) = ~10 microseconds\n```\n\n### Zero-Copy Performance\n\n```cpp\n// Per-token append:\ncache.appendToken() = O(1) counter increment\n// getKView() = O(1) pointer arithmetic\n// Total per-token overhead: <1 microsecond\n```\n\n---\n\n## Testing\n\nSee [TRITON_COMPARISON.md](docs/TRITON_COMPARISON.md) for comprehensive test suite:\n- Unit tests for allocator\n- Unit tests for cache\n- Integration tests\n- Stress tests\n\n---\n\n## References\n\n- [KV Cache Design](docs/KV_CACHE_DESIGN.md) - Architecture\n- [Triton Comparison](docs/TRITON_COMPARISON.md) - Feature parity\n- [Integration Guide](docs/KV_CACHE_INTEGRATION.md) - Usage examples\n- [Implementation Summary](KV_CACHE_IMPLEMENTATION.md) - Overview\n